{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo for using the code on Goal Oriented reccomendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](architecture_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our GAN- LSTM model takes in Event log and predicts the KPI values. A process discovery tool is used to get the process model from event log.\n",
    "Reinforcement learning agent is given the KPI predictions of trained Generator, process model(DFG graph), event log and goals. It recommends the next best action to be taken optimizing the goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: Train and Test KPI prediction model\n",
    "here we show train and testing on our GAN LSTM model, any other KPI prediction model can be used for training RL agent in part2. <br>\n",
    "We also have another KPI model (Tax et at, 2017) in ProcessSequencePrediction directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/helpdesk.csv'\n",
    "###uncomment to train-test\n",
    "# !python dl_main.py --path dataset_path --mode timestamp_prediction --prefix_s 1 --prefix_e 14 --epochs 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given trained KPI prediction model, we train the RL agent for goal-oriented recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part:2 Train and Test RL agent for next best action recommendation\n",
    "We show example on helpdesk dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to : NVIDIA GeForce GTX 1650\n",
      "Device set to : NVIDIA GeForce GTX 1650\n",
      "save checkpoint path : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest.pth\n",
      "self.unique_event [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 10\n",
      "self.max_activities  10\n",
      "self.initial_action_space  [0 1 2 3 4 5 6 7 8 9]\n",
      "num cases: 2052\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Box(0.0, 4580.0, (14,), float32)\n",
      "max timesteps per episode :  8000\n",
      "model saving frequency : 20000 timesteps\n",
      "log frequency : 16000 timesteps\n",
      "printing average reward over episodes in last : 32000 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  14\n",
      "action space dimension :  10\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a discrete action space policy\n",
      "--------------------------------------------------------------------------------------------\n",
      "PPO update frequency : 32000 timesteps\n",
      "PPO K epochs :  40\n",
      "PPO epsilon clip :  0.2\n",
      "discount factor (gamma) :  0.99\n",
      "--------------------------------------------------------------------------------------------\n",
      "optimizer learning rate actor :  0.0003\n",
      "optimizer learning rate critic :  0.001\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2021-07-06 01:10:58\n",
      "============================================================================================\n",
      "num_overall_goal_satisfied  0\n",
      "num_overall_goal_not_satisfied  0\n",
      "/home/avani/Desktop/IBM/src/rl_environment.py:151: RuntimeWarning: Mean of empty slice.\n",
      "  print(\"per case mean absolute error of timestamp(in days) \", np.array(self.per_case_error).mean())\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "per case mean absolute error of timestamp(in days)  nan\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "The accuracy of the model with the most probable event:nan\n",
      "0\n",
      "Episode : 1 \t\t Timestep : 7044 \t\t Average Reward : 0.527865460211897\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1743948\n",
      "The accuracy of the model with the most probable event:  0.5357751277683135\n",
      "percent overall goal satisfied in preds:  0.8337396392003901\n",
      "percent overall goal not satisfied in preds:  0.16626036079960996\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.0\n",
      "percent_gs_which_became_gv 0.0\n",
      "len y_pred 7044\n",
      "1\n",
      "Episode : 2 \t\t Timestep : 14088 \t\t Average Reward : 0.5267063173539039\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1829038\n",
      "The accuracy of the model with the most probable event:  0.5356331629755821\n",
      "percent overall goal satisfied in preds:  0.8322769380789858\n",
      "percent overall goal not satisfied in preds:  0.16772306192101413\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.3560606060606061\n",
      "percent_gs_which_became_gv 0.07283464566929133\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "2\n",
      "Episode : 3 \t\t Timestep : 21132 \t\t Average Reward : 0.5404313689552\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1574285\n",
      "The accuracy of the model with the most probable event:  0.5434412265758092\n",
      "percent overall goal satisfied in preds:  0.8400780107264749\n",
      "percent overall goal not satisfied in preds:  0.1599219892735251\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.35984848484848486\n",
      "percent_gs_which_became_gv 0.06824146981627296\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "3\n",
      "Episode : 4 \t\t Timestep : 28176 \t\t Average Reward : 0.5259345766739733\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1834753\n",
      "The accuracy of the model with the most probable event:  0.530664395229983\n",
      "percent overall goal satisfied in preds:  0.8322769380789858\n",
      "percent overall goal not satisfied in preds:  0.16772306192101413\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.36553030303030304\n",
      "percent_gs_which_became_gv 0.0688976377952756\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "4\n",
      "Episode : 5 \t\t Timestep : 35220 \t\t Average Reward : 0.533956266168731\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1567602\n",
      "The accuracy of the model with the most probable event:  0.5360590573537762\n",
      "percent overall goal satisfied in preds:  0.8322769380789858\n",
      "percent overall goal not satisfied in preds:  0.16772306192101413\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.3560606060606061\n",
      "percent_gs_which_became_gv 0.07020997375328084\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "5\n",
      "Episode : 6 \t\t Timestep : 42264 \t\t Average Reward : 0.5326988103734394\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1686707\n",
      "The accuracy of the model with the most probable event:  0.5374787052810903\n",
      "percent overall goal satisfied in preds:  0.8381277425646027\n",
      "percent overall goal not satisfied in preds:  0.16187225743539738\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.35795454545454547\n",
      "percent_gs_which_became_gv 0.07020997375328084\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "6\n",
      "Episode : 7 \t\t Timestep : 49308 \t\t Average Reward : 0.5290827051623196\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1972928\n",
      "The accuracy of the model with the most probable event:  0.5371947756956275\n",
      "percent overall goal satisfied in preds:  0.8361774744027304\n",
      "percent overall goal not satisfied in preds:  0.16382252559726962\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.36553030303030304\n",
      "percent_gs_which_became_gv 0.06824146981627296\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "7\n",
      "Episode : 8 \t\t Timestep : 56352 \t\t Average Reward : 0.533679796398424\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1608405\n",
      "The accuracy of the model with the most probable event:  0.5397501419647928\n",
      "percent overall goal satisfied in preds:  0.8337396392003901\n",
      "percent overall goal not satisfied in preds:  0.16626036079960996\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.36363636363636365\n",
      "percent_gs_which_became_gv 0.07020997375328084\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 9 \t\t Timestep : 63396 \t\t Average Reward : 0.5282721210105692\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.183764\n",
      "The accuracy of the model with the most probable event:  0.5381885292447472\n",
      "percent overall goal satisfied in preds:  0.8293515358361775\n",
      "percent overall goal not satisfied in preds:  0.17064846416382254\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.36742424242424243\n",
      "percent_gs_which_became_gv 0.07020997375328084\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "9\n",
      "Episode : 10 \t\t Timestep : 70440 \t\t Average Reward : 0.548279913899649\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1755342\n",
      "The accuracy of the model with the most probable event:  0.5540885860306644\n",
      "percent overall goal satisfied in preds:  0.8342272062408581\n",
      "percent overall goal not satisfied in preds:  0.1657727937591419\n",
      "percent overall goal satisfied in gt:  0.7426900584795322\n",
      "percent overall goal not satisfied in gt:  0.2573099415204678\n",
      "percent_gv_which_became_gs 0.3712121212121212\n",
      "percent_gs_which_became_gv 0.07414698162729659\n",
      "len y_pred 7044\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest.pth\n",
      "model saved\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving best model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "best model saved\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:37\n",
      "--------------------------------------------------------------------------------------------\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2021-07-06 01:10:58\n",
      "Finished training at (GMT) :  2021-07-06 01:15:35\n",
      "Total training time  :  0:04:37\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "self.unique_event [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 10\n",
      "self.max_activities  10\n",
      "self.initial_action_space  [0 1 2 3 4 5 6 7 8 9]\n",
      "num cases: 315\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Box(0.0, 4559.0, (14,), float32)\n",
      "loading network from : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "num_overall_goal_satisfied  0\n",
      "num_overall_goal_not_satisfied  0\n",
      "/home/avani/Desktop/IBM/src/rl_environment.py:151: RuntimeWarning: Mean of empty slice.\n",
      "  print(\"per case mean absolute error of timestamp(in days) \", np.array(self.per_case_error).mean())\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "per case mean absolute error of timestamp(in days)  nan\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "The accuracy of the model with the most probable event:nan\n",
      "0\n",
      "Episode: 1 \t\t Reward: 576.1\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.0522115\n",
      "The accuracy of the model with the most probable event:  0.5485921889191644\n",
      "percent overall goal satisfied in preds:  0.8057324840764332\n",
      "percent overall goal not satisfied in preds:  0.1942675159235669\n",
      "percent overall goal satisfied in gt:  0.7714285714285715\n",
      "percent overall goal not satisfied in gt:  0.22857142857142854\n",
      "percent_gv_which_became_gs 0.0\n",
      "percent_gs_which_became_gv 0.0\n",
      "len y_pred 1101\n",
      "1\n",
      "Episode: 2 \t\t Reward: 576.42\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.0634477\n",
      "The accuracy of the model with the most probable event:  0.5603996366939146\n",
      "percent overall goal satisfied in preds:  0.8152866242038217\n",
      "percent overall goal not satisfied in preds:  0.18471337579617833\n",
      "percent overall goal satisfied in gt:  0.7714285714285715\n",
      "percent overall goal not satisfied in gt:  0.22857142857142854\n",
      "percent_gv_which_became_gs 0.027777777777777776\n",
      "percent_gs_which_became_gv 0.0205761316872428\n",
      "len y_pred 1101\n",
      "2\n",
      "Episode: 3 \t\t Reward: 588.24\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.082248\n",
      "The accuracy of the model with the most probable event:  0.5758401453224341\n",
      "percent overall goal satisfied in preds:  0.8375796178343949\n",
      "percent overall goal not satisfied in preds:  0.1624203821656051\n",
      "percent overall goal satisfied in gt:  0.7714285714285715\n",
      "percent overall goal not satisfied in gt:  0.22857142857142854\n",
      "percent_gv_which_became_gs 0.027777777777777776\n",
      "percent_gs_which_became_gv 0.012345679012345678\n",
      "len y_pred 1101\n",
      "============================================================================================\n",
      "average test reward : 580.25\n",
      "============================================================================================\n",
      "self.unique_event [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 10\n",
      "self.max_activities  10\n",
      "self.initial_action_space  [0 1 2 3 4 5 6 7 8 9]\n",
      "num cases: 790\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Box(0.0, 4576.0, (14,), float32)\n",
      "loading network from : PPO_preTrained/helpdesk/PPO_helpdesk_settingtest_best_model.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "num_overall_goal_satisfied  0\n",
      "num_overall_goal_not_satisfied  0\n",
      "/home/avani/Desktop/IBM/src/rl_environment.py:151: RuntimeWarning: Mean of empty slice.\n",
      "  print(\"per case mean absolute error of timestamp(in days) \", np.array(self.per_case_error).mean())\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "per case mean absolute error of timestamp(in days)  nan\n",
      "/home/avani/anaconda3/envs/tf1/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "The accuracy of the model with the most probable event:nan\n",
      "0\n",
      "Episode: 1 \t\t Reward: 1429.81\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1671934\n",
      "The accuracy of the model with the most probable event:  0.5458832063837504\n",
      "percent overall goal satisfied in preds:  0.8111533586818758\n",
      "percent overall goal not satisfied in preds:  0.1888466413181242\n",
      "percent overall goal satisfied in gt:  0.759493670886076\n",
      "percent overall goal not satisfied in gt:  0.240506329113924\n",
      "percent_gv_which_became_gs 0.0\n",
      "percent_gs_which_became_gv 0.0\n",
      "len y_pred 2757\n",
      "1\n",
      "Episode: 2 \t\t Reward: 1469.19\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1447058\n",
      "The accuracy of the model with the most probable event:  0.552412042074719\n",
      "percent overall goal satisfied in preds:  0.8174904942965779\n",
      "percent overall goal not satisfied in preds:  0.18250950570342206\n",
      "percent overall goal satisfied in gt:  0.759493670886076\n",
      "percent overall goal not satisfied in gt:  0.240506329113924\n",
      "percent_gv_which_became_gs 0.1\n",
      "percent_gs_which_became_gv 0.03\n",
      "len y_pred 2757\n",
      "2\n",
      "Episode: 3 \t\t Reward: 1444.15\n",
      "\n",
      " \n",
      "per case mean absolute error of timestamp(in days):  3.1584222\n",
      "The accuracy of the model with the most probable event:  0.55930359085963\n",
      "percent overall goal satisfied in preds:  0.7972116603295311\n",
      "percent overall goal not satisfied in preds:  0.20278833967046894\n",
      "percent overall goal satisfied in gt:  0.759493670886076\n",
      "percent overall goal not satisfied in gt:  0.240506329113924\n",
      "percent_gv_which_became_gs 0.09473684210526316\n",
      "percent_gs_which_became_gv 0.03833333333333333\n",
      "len y_pred 2757\n",
      "============================================================================================\n",
      "average test reward : 1447.72\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python rl_main.py --train_episodes 10 --test_episodes 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checkpoints are written to PPO_Pretrained/<env_name> <br>\n",
    "logs and graphs are saved to PPO_logs/<env_name> <br>\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}